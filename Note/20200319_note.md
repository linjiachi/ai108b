# Weekly3
> Part1： \
> Part2：梯度下降法 \
> Part3：梯度下降法與神經網路
## Part1
梯度下降法

## Part2
1. [gdEquation2.py](https://github.com/ccccourse/ai/blob/master/python/03-neuralnet/03-gd/gdEquation2.py)
```md
np.linalg.norm(Y-B,1) //norm, 1 絕對值法
np.linalg.norm(Y-B,2) //norm, 2 最小平方法
```
## Part3
1. 神經網路與梯度下降法的關係
* 神經元
    - a1~an : 輸入質，輸入向量的各個分量
    - w1~wn : 神經元各個突觸的權值
    - b : 偏質
    - f : 傳遞函式，通常為非線性函式
    - t : 神經元輸出

* 神經網路
    - 神經網路 = f(w向量·a向量 + b)

---
資料來源&參考：
- [陳鍾誠老師的網站-人工智慧/03-神經網路](http://www.misavo.com/blog/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E6%9B%B8%E7%B1%8D/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/03-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF)
-[CNN（卷积神经网络）、RNN（循环神经网络）、DNN（深度神经网络）的内部网络结构有什么区别？](https://www.zhihu.com/question/34681168?fbclid=IwAR0yEtlqbYGxRRntzSCaNiPgW8YeLzwsBPe9QtcGt5BQ18w_JwWYO3wIccQ)
