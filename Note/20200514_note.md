# Weekly11
> Part1：科學計算 迭代法與不動點定理 \
> Part2、Part3：科學計算/矩陣, 特徵值與特徵向量
## Part1
1. 傅立葉轉換：對於影像處理、訊號處理有重要的地位
2. 迭代法 [Iteration](https://github.com/ccccourse/ai/blob/master/python/08-scientific/iteration/README.md)：不管式子如何最終要轉成 x = f(x) 才能使用迭代法，結果可能有收斂、發散、震盪和混沌
3. [iteration.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/iteration/iteration.py)
```py
# 計算 3 的平方根之迭代程式
# https://misavo.com/blog/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E6%9B%B8%E7%B1%8D/%E6%BC%94%E7%AE%97%E6%B3%95/04-iterative
def f1(x):
    return 3 / x
'''
f1(x) = 3 / x
 x = f(x)
 x = 3/x
 x^2 = 3
'''
def f2(x):
    return x - 1 / 4 * (x * x - 3)
'''
 f2(x) = x - 1 / 4 * (x * x - 3)
  x = f(x)
  x = x-1/4(x^2-3)
  4x = 4x-(x^2)+3
  0 = -(x^2)+3
  x^2 = 3
'''
def f3(x):
    return 1 / 2 * (x + 3 / x)
'''
 f3(x) = 1/2(x+3/x)
  x = f(x)
  x = 1/2(x^3/x)
  2x = x + 3/x
  2(x^2) = (x^2) + 3
  x^2 = 3
'''
x1 = x2 = x3 = 1
for i in range(20):
    x1 = f1(x1)
    x2 = f2(x2)
    x3 = f3(x3)
    print('x1:', x1, 'x2:', x2, 'x3:', x3)
```
* 執行結果：
    - 第一種(x1 = f1(x1))迭代情況：連續在1、3之間震盪，不會收斂
    - 第二種(x2 = f2(x2))情況：很快的收斂，在第六次就1.732...
    - 第三種(x3 = f3(x3))情況：更快的收斂，在第三次就1.732...
```c
PS C:\Users\USER\Desktop\LC_AI\ai\python\08-scientific\iteration> python .\iteration.py   
x1: 3.0 x2: 1.5 x3: 2.0
x1: 1.0 x2: 1.6875 x3: 1.75
x1: 3.0 x2: 1.7255859375 x3: 1.7321428571428572      
x1: 1.0 x2: 1.7311742305755615 x3: 1.7320508100147274
x1: 3.0 x2: 1.7319331764233397 x3: 1.7320508075688772
x1: 1.0 x2: 1.73203504452438 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320486956592371 x3: 1.7320508075688772
x1: 1.0 x2: 1.732050524625521 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320507696616354 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508024902694 x3: 1.7320508075688772
x1: 3.0 x2: 1.732050806888473 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508074777203 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320508075566647 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508075672412 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320508075686583 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508075688479 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320508075688732 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508075688767 x3: 1.7320508075688772
x1: 3.0 x2: 1.7320508075688772 x3: 1.7320508075688772
x1: 1.0 x2: 1.7320508075688772 x3: 1.7320508075688772
```
4. 爬山演算法、遺傳演算法也能看作是迭代法，而迭代法可以用來求方程式的解
5. [不動點定理](https://zh.wikipedia.org/wiki/%E4%B8%8D%E5%8A%A8%E7%82%B9%E5%AE%9A%E7%90%86)：符合 f(x) = x
6. [巴拿赫不動點定理](https://zh.wikipedia.org/wiki/%E5%B7%B4%E6%8B%BF%E8%B5%AB%E4%B8%8D%E5%8A%A8%E7%82%B9%E5%AE%9A%E7%90%86)：須滿足壓縮映射性質
* [mapFixPoint.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/iteration/mapFixPoint.py)：把小地圖重疊在大地圖上
```py
from math import *
import numpy as np
from fixPoint import fixPoint
# 範例 -- 尋找某縮小地圖的不動點。

# 旋轉函數：把 x 點以原點(0, 0)為圓心，逆時針旋轉 a 度
def rotate(x, a):
    rx = [cos(a)*x[0] - sin(a)*x[1], 
          sin(a)*x[0] + cos(a)*x[1]]
    return np.array(rx)

# 平移：把 x 移到 x+d
def move(x, d):
    return np.add(x,d)

# 放大、縮小
def scale(x, s):
    return x*s


def map(x):
    sx = scale(x, 0.2)  # 把地圖縮小成 20%
    mx = move(sx, [0.5, 0.5])   # 把中心點移到 (0.5, 0.5)
    rx = rotate(mx, pi/4)   # 再旋轉 pi/4
    return rx

# 把地圖所小成 20%，把中心點移到 (0.5, 0.5)，再旋轉 pi/4，重疊在原地圖上，去觀察是否有一點在2張地圖上為同一座標，如果有那點稱為 -> 不動點 

np.set_printoptions(precision=5,suppress=True)
p0 = np.array([0.1, 0.1])   # 設定起始點
fixPoint(map, p0, np.linalg.norm)   # 呼叫不動點程式
```
呼叫不動點函式 [fixPoint.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/iteration/fixPoint.py)
```py
def fixPoint(f, x, dist, gap = 0.0000001):
    while (True):
        fx = f(x)
        print('x=', x, 'fx=', fx)
        if dist(x-fx) < gap:
            break
        x = fx

    return x
```
* 執行結果：
```c
PS C:\Users\USER\Desktop\LC_AI\ai\python\08-scientific\iteration> python .\mapFixPoint.py
x= [0.1 0.1] fx= [0.      0.73539]
x= [0.      0.73539] fx= [-0.104    0.81111]
x= [-0.104    0.81111] fx= [-0.12942  0.80711]
x= [-0.12942  0.80711] fx= [-0.13244  0.80295]
x= [-0.13244  0.80295] fx= [-0.13228  0.80193]
x= [-0.13228  0.80193] fx= [-0.13212  0.80181]
x= [-0.13212  0.80181] fx= [-0.13208  0.80182]
x= [-0.13208  0.80182] fx= [-0.13207  0.80182]
x= [-0.13207  0.80182] fx= [-0.13207  0.80182]
x= [-0.13207  0.80182] fx= [-0.13207  0.80182]
x= [-0.13207  0.80182] fx= [-0.13207  0.80182]
```
## Part2、Part3
1. [solve1.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/matrix/solve1.py)
```py
import numpy as np
from scipy import linalg

m,n=500,50

A = np.random.rand(m, m)
B = np.random.rand(m, n)
print('A=', A)
print('B=', B)
X1 = linalg.solve(A,B)
X2 = np.dot(linalg.inv(A), B) # 用反矩陣去做 solve
print('X1=solve(A,B)=', X1)
print('X2=inv(A)*B', X2)
print('is X1==X2 ?', np.allclose(X1,X2))

'''
A X = B

3 2   a  = 5
1 1   b    2

3a+2b = 5
1a+1b = 2

inv(A) A  X = inv(A) B
I X = inv(A) B
X = inv(A) B
'''
# %timeit linalg.solve(A,B)
# %timeit np.dot(linalg.inv(A), B)
```
* 執行結果：
```c
PS C:\Users\USER\Desktop\LC_AI\ai\python\08-scientific\matrix> python .\solve1.py
A= [[0.05588975 0.12976943 0.38088679 ... 0.22435861 0.51053359 0.30318566]
 [0.65029041 0.42257497 0.63111622 ... 0.23240033 0.40321893 0.95081521]
 [0.9574641  0.09907325 0.73071942 ... 0.0650029  0.35673102 0.97745241]
 ...
 [0.19943904 0.54450252 0.85609891 ... 0.41254472 0.35894475 0.83398755]
 [0.68157291 0.3939137  0.11364491 ... 0.58938856 0.08053567 0.55793852]
 [0.48711235 0.3063992  0.12468155 ... 0.31793002 0.89523591 0.82186571]]
B= [[0.0750905  0.11194508 0.92126749 ... 0.99962147 0.65558181 0.72853864]
 [0.70071088 0.10915012 0.46713553 ... 0.0109091  0.71367626 0.86695195]
 [0.64414997 0.45073349 0.79598583 ... 0.91761114 0.5280918  0.67985683]
 ...
 [0.61556786 0.87771956 0.67281463 ... 0.59333274 0.42464074 0.45061539]
 [0.57310618 0.68251898 0.42384964 ... 0.34524333 0.53832778 0.7382963 ]
 [0.89001325 0.5973091  0.68073522 ... 0.57201233 0.2884702  0.73422358]]
X1=solve(A,B)= [[ 0.16188272 -7.9230546  -6.53163568 ... -0.34010954  1.4987499
  -0.02339534]
 [ 0.02658635 -4.39029481 -3.91006827 ...  0.21776026  1.25199997
   1.08856613]
 [-0.69289342  7.37905938  5.78452442 ... -0.52410229 -0.59182177
  -0.90944641]
 ...
 [-0.15033292 -6.57222185 -4.7281283  ...  0.14615818 -0.02076272
   0.45801823]
 [-0.75716042 -6.48932852 -4.76786618 ... -1.02570321  0.10823544
  -0.0210237 ]
 [-0.24496163 -7.50371203 -5.71469573 ... -0.37848233  0.32776938
   0.47340172]]
X2=inv(A)*B [[ 0.16188272 -7.9230546  -6.53163568 ... -0.34010954  1.4987499
  -0.02339534]
 [ 0.02658635 -4.39029481 -3.91006827 ...  0.21776026  1.25199997
   1.08856613]
 [-0.69289342  7.37905938  5.78452442 ... -0.52410229 -0.59182177
  -0.90944641]
 ...
 [-0.15033292 -6.57222185 -4.7281283  ...  0.14615818 -0.02076272
   0.45801823]
 [-0.75716042 -6.48932852 -4.76786618 ... -1.02570321  0.10823544
  -0.0210237 ]
 [-0.24496163 -7.50371203 -5.71469573 ... -0.37848233  0.32776938
   0.47340172]]
is X1==X2 ? True
```
2. 轉置
```md
M = 

a b c
d e f

M.transpose()

a d
b e
c f
```
3. [eigen1.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/matrix/eigen1.py)：
* 特徵向量 與 特徵值：
> 如果有一個非零的向量 X，A*X 結果會是 X的簡單常數倍(λ)，也就是 AX = λX，則稱 X 為 A 的特徵向量，λ 為 A 的特徵值。
```py
import numpy as np
from scipy import linalg

A = np.array([[1,   -0.3], 
              [-0.1, 0.9]])
eA = linalg.eig(A)
print('eA=\n', eA)

l, X = eA
L = np.diag(l) # 把 lambda 轉成對角矩陣
print('L=\n', L)    # L:特徵值對角矩陣
print('X=\n', X)    # X:特徵向量所形成的矩陣

XL = np.dot(X, L) # 為何用 X*L 說明在後面。
AX = np.dot(A, X)

print('XL=\n', XL)
print('AX=\n', AX) # A:矩陣、X:矩陣
print('is XL==AX ?', np.allclose(XL,AX))

'''
* 注意：以下 eigen vector X 的排列是 [x1, x2, ..., xn] ，所以 XL 才是 [l1x1, l2x2, ..., lnxn]

* 這樣的排列，確實得用 XL 才會得到所要 AX 結果。

  A1                    A1*X1 A1*X2 A1*X3
[ A2 ] [ X1 X2 X3 ] = [ A2*X1 A2*X2 A2*X3 ]
  A3                    A3*X1 A3*X2 A3*X3

A Xi = Li Xi
                             L1
A [X1 .. Xn] = [X1 ... Xn] [    L2     ]
                                  ...
    (特徵向量)  (特徵值)
矩陣*向量 = 向量*常數                                
'''
```
* 特徵值分解一定要是方陣 (n*n)
* 執行結果：
```c
PS C:\Users\USER\Desktop\LC_AI\ai\python\08-scientific\matrix> python.exe .\eigen1.py
eA=
 (array([1.13027756+0.j, 0.76972244+0.j]), array([[ 0.91724574,  0.79325185],
       [-0.3983218 ,  0.60889368]]))
L=
 [[1.13027756+0.j 0.        +0.j]
 [0.        +0.j 0.76972244+0.j]]
X=
 [[ 0.91724574  0.79325185]
 [-0.3983218   0.60889368]]
XL=
 [[ 1.03674228+0.j  0.61058374+0.j]
 [-0.45021419+0.j  0.46867912+0.j]]
AX=
 [[ 1.03674228  0.61058374]
 [-0.45021419  0.46867912]]
is XL==AX ? True
```
4. [svd1.py](https://github.com/ccccourse/ai/blob/master/python/08-scientific/matrix/svd1.py)：奇異值分解唯一數值遞減的對角線矩陣，除了對角線上的奇異質以外皆為 0，同時奇異質為非負數質。
```py
import numpy as np

a = [[1,2,3], [4,5,6]]

u,s,vh = np.linalg.svd(a, full_matrices=True)

print('u=', u, '\ns=', s, '\nvh=', vh)

ds = np.diag(s)
print('ds=', ds)
ds1 = np.append(ds, [[0],[0]], 1)
print('ds1=', ds1)
us = np.dot(u, ds1)
usvh = np.dot(us, vh)
print('usvh=', usvh)

print('is usvh==a ?', np.allclose(usvh,a))
```
* 執行結果：
```c
PS C:\Users\USER\Desktop\LC_AI\ai\python\08-scientific\matrix> python .\svd1.py   
u= [[-0.3863177  -0.92236578]
 [-0.92236578  0.3863177 ]]
s= [9.508032   0.77286964]
vh= [[-0.42866713 -0.56630692 -0.7039467 ]
 [ 0.80596391  0.11238241 -0.58119908]
 [ 0.40824829 -0.81649658  0.40824829]]
```
---
資料來源&參考：
- [陳鍾誠老師的網站-演算法/04-iterative](https://misavo.com/blog/%E9%99%B3%E9%8D%BE%E8%AA%A0/%E6%9B%B8%E7%B1%8D/%E6%BC%94%E7%AE%97%E6%B3%95/04-iterative)
- [巴拿赫不動點定理](https://zh.wikipedia.org/wiki/%E5%B7%B4%E6%8B%BF%E8%B5%AB%E4%B8%8D%E5%8A%A8%E7%82%B9%E5%AE%9A%E7%90%86)
- [不動點定理](https://zh.wikipedia.org/wiki/%E4%B8%8D%E5%8A%A8%E7%82%B9%E5%AE%9A%E7%90%86)
- [旋轉矩陣](https://zh.wikipedia.org/wiki/%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5)
- [特徵值和特徵向量](https://zh.wikipedia.org/wiki/%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F)
- [奇異值分解](https://zh.wikipedia.org/zh-tw/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3)